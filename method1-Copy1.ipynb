{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack 10 Opt Flows + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import caffe\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "def load_list(data_dir, prefix = None, dataset = 1):\n",
    "    train_list = os.path.join(data_dir, 'train') + str(dataset) + '.idx'\n",
    "    test_list = os.path.join(data_dir, 'test') + str(dataset) + '.idx'\n",
    "    with open(train_list) as f:\n",
    "        train_list = f.read().splitlines()\n",
    "    with open(test_list) as f:\n",
    "        test_list = f.read().splitlines()\n",
    "    if prefix is not None:\n",
    "        train_list = map(lambda x: os.path.join(prefix, x), train_list)\n",
    "        test_list = map(lambda x: os.path.join(prefix, x), test_list)\n",
    "    return train_list, test_list\n",
    "\n",
    "def load_img(filename, flip = False, grayscale = False):\n",
    "    if grayscale:\n",
    "        img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        img = cv2.imread(filename)\n",
    "    if flip:\n",
    "        img = cv2.flip(img, 1)\n",
    "    if grayscale:\n",
    "        width, height = img.shape\n",
    "    else:\n",
    "        width, height, _ = img.shape\n",
    "    factor = max(256.0 / width, 256.0 / height)\n",
    "    img = cv2.resize(img, None, fx = factor, fy = factor)\n",
    "    return img\n",
    "\n",
    "def load_imgs(filenames, reverse = False, flip = False, grayscale = False):\n",
    "    if reverse:\n",
    "        filenames = filenames[::-1]\n",
    "    imgs = map(lambda x: load_img(x, flip, grayscale), filenames)\n",
    "    return imgs\n",
    "\n",
    "def load_video(video, data_dir, mask = None, reverse = False, flip = False, grayscale = False):\n",
    "    filenames = os.listdir(os.path.join(data_dir, video))\n",
    "    filenames = filter(lambda x: x[-4:] == 'jpeg', filenames)\n",
    "    if mask is not None:\n",
    "        filenames = filter(mask, filenames)\n",
    "    filenames.sort()\n",
    "    filenames = map(lambda x: os.path.join(data_dir, video, x), filenames)\n",
    "    imgs = load_imgs(filenames, reverse, flip, grayscale)\n",
    "    return imgs\n",
    "\n",
    "def is_forward(video):\n",
    "    if video[0] == 'F':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def select(imgs):\n",
    "    #mags = [None] * (len(imgs)/2)\n",
    "    #for i in range(len(imgs)/2):\n",
    "    #    mag, _ = cv2.cartToPolar(np.asarray(imgs[2*i], dtype = np.float32), np.asarray(imgs[2*i+1], dtype = np.float32))\n",
    "    #mags[i] = cv2.norm(mag)\n",
    "    #mags = np.asarray(mags)\n",
    "    #idx = np.argsort(mags)[::-1][:10]\n",
    "    idx = np.random.choice(len(imgs)/2, 10)\n",
    "    indices = [None] * 20\n",
    "    for i in range(10):\n",
    "        indices[2*i] = 2*idx[i]\n",
    "        indices[2*i+1] = 2*idx[i]+1\n",
    "    image = np.take(np.asarray(imgs), indices, axis = 0)\n",
    "    return image\n",
    "\n",
    "def load_flows(video):\n",
    "    images = []\n",
    "    if is_forward(video):\n",
    "        imgs = load_video(video, './data/ArrowDataAll', mask = lambda x: x[:3] == 'off', grayscale=True)\n",
    "        imgs = map(lambda x: cv2.resize(x, (227, 227)), imgs)\n",
    "        images.append(select(imgs))\n",
    "\n",
    "        imgs = load_video(video, './data/ArrowDataAll', mask = lambda x: x[:3] == 'off', flip = True, grayscale=True)\n",
    "        imgs = map(lambda x: cv2.resize(x, (227, 227)), imgs)\n",
    "        images.append(select(imgs))\n",
    "\n",
    "        imgs = load_video(video, './data/ArrowDataAll', mask = lambda x: x[:3] == 'ofb', grayscale=True)\n",
    "        imgs = map(lambda x: cv2.resize(x, (227, 227)), imgs)\n",
    "        images.append(select(imgs))\n",
    "        \n",
    "        imgs = load_video(video, './data/ArrowDataAll', mask = lambda x: x[:3] == 'ofb', flip = True, grayscale=True)\n",
    "        imgs = map(lambda x: cv2.resize(x, (227, 227)), imgs)\n",
    "        images.append(select(imgs))\n",
    "\n",
    "        labels = [1, 1, 0, 0]\n",
    "    else:\n",
    "        imgs = load_video(video, './data/ArrowDataAll', mask = lambda x: x[:3] == 'ofb', grayscale=True)\n",
    "        imgs = map(lambda x: cv2.resize(x, (227, 227)), imgs)\n",
    "        images.append(select(imgs))\n",
    "        \n",
    "        imgs = load_video(video, './data/ArrowDataAll', mask = lambda x: x[:3] == 'ofb', flip = True, grayscale=True)\n",
    "        imgs = map(lambda x: cv2.resize(x, (227, 227)), imgs)\n",
    "        images.append(select(imgs))\n",
    "\n",
    "        imgs = load_video(video, './data/ArrowDataAll', mask = lambda x: x[:3] == 'off', grayscale=True)\n",
    "        imgs = map(lambda x: cv2.resize(x, (227, 227)), imgs)\n",
    "        images.append(select(imgs))\n",
    "\n",
    "        imgs = load_video(video, './data/ArrowDataAll', mask = lambda x: x[:3] == 'off', flip = True, grayscale=True)\n",
    "        imgs = map(lambda x: cv2.resize(x, (227, 227)), imgs)\n",
    "        images.append(select(imgs))\n",
    "\n",
    "        labels = [0, 0, 1, 1]\n",
    "    return np.asarray(images), np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "# load original model\n",
    "model_def = 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "model_weights = 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "net = caffe.Net(model_def, model_weights, caffe.TEST) \n",
    "# mean the conv1 layer across the 3 channels\n",
    "conv1_mean = net.params['conv1'][0].data.mean(axis = 1)\n",
    "# duplicate 20 times to handle 20-channel input data\n",
    "conv1_stack = np.repeat(conv1_mean[:, np.newaxis, :, :], 20, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load modified model \n",
    "# with layers later than fc7 removed\n",
    "model_def = 'models/caffenet/deploy.prototxt'\n",
    "model_weights = 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "net = caffe.Net(model_def, model_weights, caffe.TEST) \n",
    "# network surgery\n",
    "net.params['conv1-stack'][0].data[...] = conv1_stack\n",
    "net.blobs['data'].reshape(4, 20, 227, 227)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing video 1 / 120\n",
      "[INFO] processing video 2 / 120\n",
      "[INFO] processing video 3 / 120\n",
      "[INFO] processing video 4 / 120\n",
      "[INFO] processing video 5 / 120\n",
      "[INFO] processing video 6 / 120\n",
      "[INFO] processing video 7 / 120\n",
      "[INFO] processing video 8 / 120\n",
      "[INFO] processing video 9 / 120\n",
      "[INFO] processing video 10 / 120\n",
      "[INFO] processing video 11 / 120\n",
      "[INFO] processing video 12 / 120\n",
      "[INFO] processing video 13 / 120\n",
      "[INFO] processing video 14 / 120\n",
      "[INFO] processing video 15 / 120\n",
      "[INFO] processing video 16 / 120\n",
      "[INFO] processing video 17 / 120\n",
      "[INFO] processing video 18 / 120\n",
      "[INFO] processing video 19 / 120\n",
      "[INFO] processing video 20 / 120\n",
      "[INFO] processing video 21 / 120\n",
      "[INFO] processing video 22 / 120\n",
      "[INFO] processing video 23 / 120\n",
      "[INFO] processing video 24 / 120\n",
      "[INFO] processing video 25 / 120\n",
      "[INFO] processing video 26 / 120\n",
      "[INFO] processing video 27 / 120\n",
      "[INFO] processing video 28 / 120\n",
      "[INFO] processing video 29 / 120\n",
      "[INFO] processing video 30 / 120\n",
      "[INFO] processing video 31 / 120\n",
      "[INFO] processing video 32 / 120\n",
      "[INFO] processing video 33 / 120\n",
      "[INFO] processing video 34 / 120\n",
      "[INFO] processing video 35 / 120\n",
      "[INFO] processing video 36 / 120\n",
      "[INFO] processing video 37 / 120\n",
      "[INFO] processing video 38 / 120\n",
      "[INFO] processing video 39 / 120\n",
      "[INFO] processing video 40 / 120\n",
      "[INFO] processing video 41 / 120\n",
      "[INFO] processing video 42 / 120\n",
      "[INFO] processing video 43 / 120\n",
      "[INFO] processing video 44 / 120\n",
      "[INFO] processing video 45 / 120\n",
      "[INFO] processing video 46 / 120\n",
      "[INFO] processing video 47 / 120\n",
      "[INFO] processing video 48 / 120\n",
      "[INFO] processing video 49 / 120\n",
      "[INFO] processing video 50 / 120\n",
      "[INFO] processing video 51 / 120\n",
      "[INFO] processing video 52 / 120\n",
      "[INFO] processing video 53 / 120\n",
      "[INFO] processing video 54 / 120\n",
      "[INFO] processing video 55 / 120\n",
      "[INFO] processing video 56 / 120\n",
      "[INFO] processing video 57 / 120\n",
      "[INFO] processing video 58 / 120\n",
      "[INFO] processing video 59 / 120\n",
      "[INFO] processing video 60 / 120\n",
      "[INFO] processing video 61 / 120\n",
      "[INFO] processing video 62 / 120\n",
      "[INFO] processing video 63 / 120\n",
      "[INFO] processing video 64 / 120\n",
      "[INFO] processing video 65 / 120\n",
      "[INFO] processing video 66 / 120\n",
      "[INFO] processing video 67 / 120\n",
      "[INFO] processing video 68 / 120\n",
      "[INFO] processing video 69 / 120\n",
      "[INFO] processing video 70 / 120\n",
      "[INFO] processing video 71 / 120\n",
      "[INFO] processing video 72 / 120\n",
      "[INFO] processing video 73 / 120\n",
      "[INFO] processing video 74 / 120\n",
      "[INFO] processing video 75 / 120\n",
      "[INFO] processing video 76 / 120\n",
      "[INFO] processing video 77 / 120\n",
      "[INFO] processing video 78 / 120\n",
      "[INFO] processing video 79 / 120\n",
      "[INFO] processing video 80 / 120\n",
      "[INFO] processing video 81 / 120\n",
      "[INFO] processing video 82 / 120\n",
      "[INFO] processing video 83 / 120\n",
      "[INFO] processing video 84 / 120\n",
      "[INFO] processing video 85 / 120\n",
      "[INFO] processing video 86 / 120\n",
      "[INFO] processing video 87 / 120\n",
      "[INFO] processing video 88 / 120\n",
      "[INFO] processing video 89 / 120\n",
      "[INFO] processing video 90 / 120\n",
      "[INFO] processing video 91 / 120\n",
      "[INFO] processing video 92 / 120\n",
      "[INFO] processing video 93 / 120\n",
      "[INFO] processing video 94 / 120\n",
      "[INFO] processing video 95 / 120\n",
      "[INFO] processing video 96 / 120\n",
      "[INFO] processing video 97 / 120\n",
      "[INFO] processing video 98 / 120\n",
      "[INFO] processing video 99 / 120\n",
      "[INFO] processing video 100 / 120\n",
      "[INFO] processing video 101 / 120\n",
      "[INFO] processing video 102 / 120\n",
      "[INFO] processing video 103 / 120\n",
      "[INFO] processing video 104 / 120\n",
      "[INFO] processing video 105 / 120\n",
      "[INFO] processing video 106 / 120\n",
      "[INFO] processing video 107 / 120\n",
      "[INFO] processing video 108 / 120\n",
      "[INFO] processing video 109 / 120\n",
      "[INFO] processing video 110 / 120\n",
      "[INFO] processing video 111 / 120\n",
      "[INFO] processing video 112 / 120\n",
      "[INFO] processing video 113 / 120\n",
      "[INFO] processing video 114 / 120\n",
      "[INFO] processing video 115 / 120\n",
      "[INFO] processing video 116 / 120\n",
      "[INFO] processing video 117 / 120\n",
      "[INFO] processing video 118 / 120\n",
      "[INFO] processing video 119 / 120\n",
      "[INFO] processing video 120 / 120\n"
     ]
    }
   ],
   "source": [
    "# load list 1\n",
    "train_list, test_list = load_list('./data', dataset = 1)\n",
    "X_train = np.empty((0, 4096))\n",
    "y_train = np.empty(0)\n",
    "for train in train_list:\n",
    "    print '[INFO] processing video %d / %d' % (train_list.index(train) + 1, len(train_list))\n",
    "    images, labels = load_flows(train)\n",
    "    images -= 128*np.ones_like(images)\n",
    "    net.blobs['data'].data[...] = images\n",
    "    output = net.forward()\n",
    "    X_train = np.append(X_train, output['fc7'], axis = 0)\n",
    "    y_train = np.append(y_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing video 1 / 60\n",
      "[INFO] processing video 2 / 60\n",
      "[INFO] processing video 3 / 60\n",
      "[INFO] processing video 4 / 60\n",
      "[INFO] processing video 5 / 60\n",
      "[INFO] processing video 6 / 60\n",
      "[INFO] processing video 7 / 60\n",
      "[INFO] processing video 8 / 60\n",
      "[INFO] processing video 9 / 60\n",
      "[INFO] processing video 10 / 60\n",
      "[INFO] processing video 11 / 60\n",
      "[INFO] processing video 12 / 60\n",
      "[INFO] processing video 13 / 60\n",
      "[INFO] processing video 14 / 60\n",
      "[INFO] processing video 15 / 60\n",
      "[INFO] processing video 16 / 60\n",
      "[INFO] processing video 17 / 60\n",
      "[INFO] processing video 18 / 60\n",
      "[INFO] processing video 19 / 60\n",
      "[INFO] processing video 20 / 60\n",
      "[INFO] processing video 21 / 60\n",
      "[INFO] processing video 22 / 60\n",
      "[INFO] processing video 23 / 60\n",
      "[INFO] processing video 24 / 60\n",
      "[INFO] processing video 25 / 60\n",
      "[INFO] processing video 26 / 60\n",
      "[INFO] processing video 27 / 60\n",
      "[INFO] processing video 28 / 60\n",
      "[INFO] processing video 29 / 60\n",
      "[INFO] processing video 30 / 60\n",
      "[INFO] processing video 31 / 60\n",
      "[INFO] processing video 32 / 60\n",
      "[INFO] processing video 33 / 60\n",
      "[INFO] processing video 34 / 60\n",
      "[INFO] processing video 35 / 60\n",
      "[INFO] processing video 36 / 60\n",
      "[INFO] processing video 37 / 60\n",
      "[INFO] processing video 38 / 60\n",
      "[INFO] processing video 39 / 60\n",
      "[INFO] processing video 40 / 60\n",
      "[INFO] processing video 41 / 60\n",
      "[INFO] processing video 42 / 60\n",
      "[INFO] processing video 43 / 60\n",
      "[INFO] processing video 44 / 60\n",
      "[INFO] processing video 45 / 60\n",
      "[INFO] processing video 46 / 60\n",
      "[INFO] processing video 47 / 60\n",
      "[INFO] processing video 48 / 60\n",
      "[INFO] processing video 49 / 60\n",
      "[INFO] processing video 50 / 60\n",
      "[INFO] processing video 51 / 60\n",
      "[INFO] processing video 52 / 60\n",
      "[INFO] processing video 53 / 60\n",
      "[INFO] processing video 54 / 60\n",
      "[INFO] processing video 55 / 60\n",
      "[INFO] processing video 56 / 60\n",
      "[INFO] processing video 57 / 60\n",
      "[INFO] processing video 58 / 60\n",
      "[INFO] processing video 59 / 60\n",
      "[INFO] processing video 60 / 60\n"
     ]
    }
   ],
   "source": [
    "X_test = np.empty((0, 4096))\n",
    "y_test = np.empty(0)\n",
    "for test in test_list:\n",
    "    print '[INFO] processing video %d / %d' % (test_list.index(test) + 1, len(test_list))\n",
    "    images, labels = load_flows(test)\n",
    "    images -= 128*np.ones_like(images)\n",
    "    net.blobs['data'].data[...] = images\n",
    "    output = net.forward()\n",
    "    X_test = np.append(X_test, output['fc7'], axis = 0)\n",
    "    y_test = np.append(y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw precision 0.479167\n"
     ]
    }
   ],
   "source": [
    "print 'raw precision %f' % lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 1000)\n",
    "pca.fit(X_train)\n",
    "X_train_reduct = pca.transform(X_train)\n",
    "X_test_reduct = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train_reduct, y_train)\n",
    "print rfc.score(X_train_reduct, y_train)\n",
    "print rfc.score(X_test_reduct, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(rfc.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_jobs = -1)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_ = svc.predict(X_test)\n",
    "y_predict = np.empty(len(y_predict_) / 4)\n",
    "y_test = np.empty(len(y_predict))\n",
    "for i in range(len(y_predict)):\n",
    "    k = 4*i\n",
    "    y_predict[i] = y_predict_[k] + y_predict_[k+1] - y_predict_[k+2] - y_predict_[k+3]\n",
    "    y_test[i] = y_test_[k]\n",
    "y_predict = np.sign(y_predict + 0.5)\n",
    "precision = np.sum(y_predict == y_test) / float(len(y_test))\n",
    "print 'Precision of dataset %d: %f' % (dataset, precision)\n",
    "return precisionsvc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
