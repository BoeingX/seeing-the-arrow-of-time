{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import caffe\n",
    "import os\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_list(data_dir, prefix = None, dataset = 1):\n",
    "    train_list = os.path.join(data_dir, 'train') + str(dataset) + '.idx'\n",
    "    test_list = os.path.join(data_dir, 'test') + str(dataset) + '.idx'\n",
    "    with open(train_list) as f:\n",
    "        train_list = f.read().splitlines()\n",
    "    with open(test_list) as f:\n",
    "        test_list = f.read().splitlines()\n",
    "    if prefix is not None:\n",
    "        train_list = map(lambda x: os.path.join(prefix, x), train_list)\n",
    "        test_list = map(lambda x: os.path.join(prefix, x), test_list)\n",
    "    return train_list, test_list\n",
    "\n",
    "def load_img(filename, flip = False, grayscale = False):\n",
    "    if grayscale:\n",
    "        img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        img = cv2.imread(filename)\n",
    "    if flip:\n",
    "        img = cv2.flip(img, 1)\n",
    "    if grayscale:\n",
    "        width, height = img.shape\n",
    "    else:\n",
    "        width, height, _ = img.shape\n",
    "    factor = max(256.0 / width, 256.0 / height)\n",
    "    img = cv2.resize(img, None, fx = factor, fy = factor)\n",
    "    return img\n",
    "\n",
    "def load_imgs(filenames, reverse = False, flip = False, grayscale = False):\n",
    "    if reverse:\n",
    "        filenames = filenames[::-1]\n",
    "    imgs = map(lambda x: load_img(x, flip, grayscale), filenames)\n",
    "    return imgs\n",
    "\n",
    "def load_video(video, data_dir, mask = None, reverse = False, flip = False, grayscale = False):\n",
    "    filenames = os.listdir(os.path.join(data_dir, video))\n",
    "    filenames = filter(lambda x: x[-4:] == 'jpeg', filenames)\n",
    "    if mask is not None:\n",
    "        filenames = filter(mask, filenames)\n",
    "    filenames.sort()\n",
    "    filenames = map(lambda x: os.path.join(data_dir, video, x), filenames)\n",
    "    imgs = load_imgs(filenames, reverse, flip, grayscale)\n",
    "    return imgs\n",
    "\n",
    "def is_forward(video):\n",
    "    if video[0] == 'F':\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_flows(video):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for direction in ['f', 'b']:\n",
    "        for flip in [False, True]:\n",
    "            imgs_ = load_video(video, './data/ArrowDataAll', \n",
    "                               mask = lambda x: x[:3] == 'of' + direction, \n",
    "                               flip = flip, \n",
    "                               grayscale=True)\n",
    "            imgs_ = map(lambda x: cv2.resize(x, (227, 227)), imgs_)\n",
    "            imgs = []\n",
    "            for i in range(len(imgs_)/2):\n",
    "                imgs.append(np.asarray([imgs_[2*i], imgs_[2*i+1]]))\n",
    "            images.extend(imgs)\n",
    "            if direction == 'f':\n",
    "                labels.extend([1]*len(imgs))\n",
    "            else:\n",
    "                labels.extend([0]*len(imgs))\n",
    "    images = np.asarray(images)\n",
    "    return images, np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_optimal_batch(n):\n",
    "    n_opt = 4\n",
    "    i = 4\n",
    "    while i <= min(n, 20):\n",
    "        if n % i == 0:\n",
    "            n_opt = i\n",
    "        i += 4\n",
    "    return n_opt\n",
    "\n",
    "def forward(videos, net):\n",
    "    X = np.empty((0, 4096))\n",
    "    y = np.empty(0)\n",
    "    video_names = []\n",
    "    for video in videos:\n",
    "        print '[INFO] processing video %d / %d' % (videos.index(video) + 1, len(videos))\n",
    "        images, labels = load_flows(video)\n",
    "        images -= 128*np.ones_like(images)\n",
    "        n_opt = find_optimal_batch(len(images))\n",
    "        print '[INFO] %d images' % len(images)\n",
    "        print '[INFO] processing batch of %d' % n_opt\n",
    "        net.blobs['data'].reshape(n_opt, 2, 227, 227)\n",
    "        for i in range(len(images)/n_opt):\n",
    "            net.blobs['data'].data[...] = images[n_opt*i:n_opt*(i+1),...]\n",
    "            output = net.forward()\n",
    "            X = np.append(X, output['fc7'], axis = 0)\n",
    "        y = np.append(y, labels)\n",
    "        video_names.extend([video] * len(labels))\n",
    "    return X, y, video_names\n",
    "\n",
    "def forward_save(videos, net):\n",
    "    for video in videos:\n",
    "        print '[INFO] processing vtrain_list, test_list = load_list('./data', dataset = 1)ideo %d / %d' % (videos.index(video) + 1, len(videos))\n",
    "        X = np.empty((0, 4096))\n",
    "        y = np.empty(0)\n",
    "        images, labels = load_flows(video)\n",
    "        images -= 128*np.ones_like(images)\n",
    "        n_opt = find_optimal_batch(len(images))\n",
    "        print '[INFO] %d images' % len(images)\n",
    "        print '[INFO] processing batch of %d' % n_opt\n",
    "        net.blobs['data'].reshape(n_opt, 2, 227, 227)\n",
    "        for i in range(len(images)/n_opt):\n",
    "            net.blobs['data'].data[...] = images[n_opt*i:n_opt*(i+1),...]\n",
    "            output = net.forward()\n",
    "            X = np.append(X, output['fc7'], axis = 0)\n",
    "        y = np.append(y, labels)\n",
    "        with open(os.path.join('./data/ArrowDataAll', video, 'features.csv'), 'w') as f:\n",
    "            np.savetxt(f, X, delimiter = ',', fmt = '%f')\n",
    "        with open(os.path.join('./data/ArrowDataAll', video, 'labels.csv'), 'w') as f:\n",
    "            np.savetxt(f, y, delimiter = ',', fmt = '%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_features(video):\n",
    "    with open(os.path.join('./data/ArrowDataAll', video, 'features.csv'), 'r') as f:\n",
    "        X = np.loadtxt(f, delimiter = ',')\n",
    "    with open(os.path.join('./data/ArrowDataAll', video, 'labels.csv'), 'r') as f:\n",
    "        y = np.loadtxt(f, delimiter = ',')\n",
    "    video_names_with_multitude = [video] * len(y)\n",
    "    return X, y, video_names_with_multitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_list, test_list = load_list('./data', dataset = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "X_train = np.empty((0, 4096))\n",
    "y_train = np.empty(0)\n",
    "video_train = []\n",
    "for video in train_list[:60]:\n",
    "    print train_list.index(video)+1\n",
    "    X, y, video_names_with_multitude = load_features(video)\n",
    "    X_train = np.append(X_train, X, axis = 0)\n",
    "    y_train = np.append(y_train, y, axis = 0)\n",
    "    video_train.extend(video_names_with_multitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "X_test = np.empty((0, 4096))\n",
    "y_test = np.empty(0)\n",
    "video_test = []\n",
    "for video in test_list[:30]:\n",
    "    print test_list.index(video)+1\n",
    "    X, y, video_names_with_multitude = load_features(video)\n",
    "    X_test = np.append(X_test, X, axis = 0)\n",
    "    y_test = np.append(y_test, y, axis = 0)\n",
    "    video_test.extend(video_names_with_multitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 10)\n",
    "pca.fit(X_train)\n",
    "X_train_reduct = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99032152230971127"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48768, 4096)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24696, 4096)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_gpu()\n",
    "# load original model\n",
    "model_def = 'models/bvlc_reference_caffenet/deploy.prototxt'\n",
    "model_weights = 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "net = caffe.Net(model_def, model_weights, caffe.TEST) \n",
    "# mean the conv1 layer across the 3 channels\n",
    "conv1_mean = net.params['conv1'][0].data.mean(axis = 1)\n",
    "conv1_stack = np.repeat(conv1_mean[:, np.newaxis, :, :], 2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load modified model \n",
    "# with layers later than fc7 removed\n",
    "model_def = 'models/caffenet2/deploy.prototxt'\n",
    "model_weights = 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "net = caffe.Net(model_def, model_weights, caffe.TEST) \n",
    "# network surgery\n",
    "net.params['conv1-stack'][0].data[...] = conv1_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = SVC(kernel = 'rbf')\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'raw precision %f' % svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 1000)\n",
    "pca.fit(X_train)\n",
    "X_train_reduct = pca.transform(X_train)\n",
    "X_test_reduct = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train_reduct, y_train)\n",
    "print rfc.score(X_train_reduct, y_train)\n",
    "print rfc.score(X_test_reduct, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(rfc.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_jobs = -1)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict_ = svc.predict(X_test)\n",
    "y_predict = np.empty(len(y_predict_) / 4)\n",
    "y_test = np.empty(len(y_predict))\n",
    "for i in range(len(y_predict)):\n",
    "    k = 4*i\n",
    "    y_predict[i] = y_predict_[k] + y_predict_[k+1] - y_predict_[k+2] - y_predict_[k+3]\n",
    "    y_test[i] = y_test_[k]\n",
    "y_predict = np.sign(y_predict + 0.5)\n",
    "precision = np.sum(y_predict == y_test) / float(len(y_test))\n",
    "print 'Precision of dataset %d: %f' % (dataset, precision)\n",
    "return precisionsvc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
