{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helper import *\n",
    "%matplotlib inline\n",
    "# set display defaults\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select(imgs, n = 3, fold = 10):\n",
    "    mags = [None] * (len(imgs)/2)\n",
    "    for i in range(len(imgs)/2):\n",
    "        mag, _ = cv2.cartToPolar(np.asarray(imgs[2*i], dtype = np.float32), np.asarray(imgs[2*i+1], dtype = np.float32))\n",
    "        mags[i] = cv2.norm(mag)\n",
    "    mags = np.asarray(mags)\n",
    "    mags /= np.sum(mags)\n",
    "    idx = []\n",
    "    tmp = np.random.choice(len(mags), fold*n, replace=False, p = mags)\n",
    "    idx = np.sort(tmp).reshape(-1, 3)\n",
    "    return np.asarray(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe_root = '/home/bysong/caffe/'\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "model_def = './models/caffenet_siamese_cam/deploy.prototxt'\n",
    "model_weights = './models/caffenet_siamese_cam/caffenet_train_iter_18174.caffemodel'\n",
    "net = caffe.Net(model_def, model_weights, caffe.TEST) \n",
    "                                                                                 \n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2, 0, 1))\n",
    "transformer.set_mean('data', np.ones(3)*np.mean(np.load('./data/mean.npy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.blobs['triple_data'].reshape(fold, 9, 227, 227)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list, test_list = load_list('./data', dataset = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video = train_list[0]\n",
    "print video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reverse = False\n",
    "flip = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (is_forward(video) and (not reverse)) or ((not is_forward(video)) and reverse):\n",
    "    direction = 'f'\n",
    "else:\n",
    "    direction = 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgs = load_video(video, './data/ArrowDataAll/', mask = lambda x: x[:2] == 'im', grayscale = False, reverse = False, flip = flip)\n",
    "flows = load_video(video, './data/ArrowDataAll/', mask = lambda x: x[:3] == 'off', grayscale = True, flip = flip, reverse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sel = select(flows, fold = fold)\n",
    "if reverse:\n",
    "    sel = sel[::-1]\n",
    "images = []\n",
    "for idx in sel:\n",
    "    img = np.take(imgs, idx, axis = 0)\n",
    "    img = map(lambda x: transformer.preprocess('data', x), img)\n",
    "    img = np.asarray(np.concatenate(img, axis = 0))\n",
    "    images.append(img)\n",
    "images = np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.blobs['triple_data'].data[...] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.sum(net.blobs['prob'].data, axis = 0)\n",
    "direction = np.sum(net.blobs['prob'].data, axis = 0).argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class activation map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sz = imgs[0].shape[:2]\n",
    "t = 511\n",
    "plt.imshow(cv2.resize(net.blobs['conv7'].data[0][t], sz[::-1]))\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../report/figs/cam/' + video + '-conv7-' + str(t) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img[0].shape[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = np.take(imgs, sel[0], axis = 0)\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.imshow(img[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "direction = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sz = img[0].shape[:2]\n",
    "n_figs = 1\n",
    "for i in range(n_figs):\n",
    "    w = net.params['fc9'][0].data[direction][512*i:512*(i+1)]\n",
    "    cam = np.zeros(sz)\n",
    "    for j in range(512):\n",
    "        if i == 0:\n",
    "            cam += w[j]*cv2.resize(net.blobs['conv7'].data[0][j], sz[::-1])\n",
    "        elif i == 1:\n",
    "            cam += w[j]*cv2.resize(net.blobs['conv7_p'].data[0][j], sz[::-1])\n",
    "        else:\n",
    "            cam += w[j]*cv2.resize(net.blobs['conv7_q'].data[0][j], sz[::-1])\n",
    "    plt.subplot(1,n_figs,i+1)\n",
    "    plt.imshow(cv2.cvtColor(img[i], cv2.COLOR_BGR2RGB))\n",
    "    plt.imshow(np.abs(cam), alpha = 0.5)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../report/figs/cam/' + video + '-cam-' + str(n_figs) + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
